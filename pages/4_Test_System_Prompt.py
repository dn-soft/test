import streamlit as st
from utils import load_system_prompts, get_available_models, save_system_prompt
import json
from datetime import datetime
from litellm import completion

st.title("ğŸ§ª ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸")

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
system_prompts = load_system_prompts()

# ì‚¬ì´ë“œë°”ì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
st.sidebar.header("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ")
if not system_prompts:
    st.sidebar.warning("ì €ì¥ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
else:
    prompt_names = [p['name'] for p in system_prompts]
    selected_prompt_name = st.sidebar.selectbox("í…ŒìŠ¤íŠ¸í•  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ:", prompt_names)

    # ì„ íƒëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
    selected_prompt_content = next(p['content'] for p in system_prompts if p['name'] == selected_prompt_name)

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ëœ ë³€ìˆ˜ ì¶”ì¶œ
    variables = {}
    variable_names = [var.strip('{}') for var in selected_prompt_content.split() if '{' in var and '}' in var]

    # ë³€ìˆ˜ ì…ë ¥ í•„ë“œ ìƒì„±
    for var in variable_names:
        variables[var] = st.sidebar.text_input(f"{var} ê°’ì„ ì…ë ¥í•˜ì„¸ìš”:", "")

# ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë¸ ì„ íƒ ë° íŒŒë¼ë¯¸í„° ì„¤ì •
st.sidebar.header("ëª¨ë¸ ë° íŒŒë¼ë¯¸í„° ì„¤ì •")
model = st.sidebar.selectbox("ëª¨ë¸ ì„ íƒ:", get_available_models())
temperature = st.sidebar.slider("Temperature:", min_value=0.0, max_value=1.0, value=0.7, step=0.1)
max_tokens = st.sidebar.number_input("ìµœëŒ€ í† í° ìˆ˜:", min_value=1, max_value=4096, value=150, step=1)
top_p = st.sidebar.slider("Top P:", min_value=0.0, max_value=1.0, value=1.0, step=0.1)

# JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸° ì˜µì…˜
use_json_format = st.sidebar.checkbox("JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸°", value=False)

# ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
    st.session_state.total_round = 0  # ì´ ë¼ìš´ë“œ ìˆ˜ ì´ˆê¸°í™”

# ì‚¬ìš©ì ì…ë ¥
user_input = st.text_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", "")

# AI ì‘ë‹µ ë²„íŠ¼
if st.button("AI ì‘ë‹µ ë°›ê¸°"):
    if user_input:
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë³€ìˆ˜ ëŒ€ì²´
        prompt_with_variables = selected_prompt_content
        for var, value in variables.items():
            prompt_with_variables = prompt_with_variables.replace(f"{{{var}}}", value)

        # AIì™€ì˜ ëŒ€í™” êµ¬ì„±
        messages = [
            {"role": "system", "content": prompt_with_variables}
        ] + st.session_state.chat_history + [{"role": "user", "content": user_input}]

        # AI ì‘ë‹µ ìš”ì²­
        with st.spinner("AI ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘..."):
            response = completion(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                top_p=top_p,
                stream=False
            )

        # AI ì‘ë‹µ í‘œì‹œ
        ai_response = response.choices[0].message.content
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        st.session_state.chat_history.append({"role": "assistant", "content": ai_response})

        # ì´ ë¼ìš´ë“œ ìˆ˜ ì¦ê°€
        st.session_state.total_round += 1

        # ì‚¬ìš©ì ì…ë ¥ ë° AI ì‘ë‹µ í‘œì‹œ
        st.chat_message("user").markdown(user_input)
        st.chat_message("assistant").markdown(ai_response)

        # ì‚¬ìš©ì ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”
        st.rerun()  # í˜ì´ì§€ ìƒˆë¡œ ê³ ì¹¨

    else:
        st.error("ì‚¬ìš©ì ì…ë ¥ì„ ì…ë ¥í•˜ì„¸ìš”.")

# ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ (ìµœì‹  ë©”ì‹œì§€ê°€ ì•„ë˜ì— ì˜¤ë„ë¡)
for chat in reversed(st.session_state.chat_history):
    with st.chat_message(chat["role"]):
        st.markdown(chat["content"])

# ì‚¬ì´ë“œë°”ì— ì±„íŒ… íˆìŠ¤í† ë¦¬ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
with st.sidebar:
    st.markdown("### ì±„íŒ… íˆìŠ¤í† ë¦¬ ë‹¤ìš´ë¡œë“œ")
    if st.button("ì±„íŒ… íˆìŠ¤í† ë¦¬ ë‹¤ìš´ë¡œï¿½ï¿½ï¿½ (JSON)"):
        chat_history_json = json.dumps(st.session_state.chat_history, ensure_ascii=False, indent=2)
        st.download_button(
            label="ì±„íŒ… íˆìŠ¤í† ë¦¬ ë‹¤ìš´ë¡œë“œ",
            data=chat_history_json,
            file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )

# ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
if st.sidebar.button("ğŸ—‘ï¸ ì±„íŒ… ì´ˆê¸°í™”"):
    st.session_state.chat_history = []
    st.session_state.total_round = 0  # ì´ ë¼ìš´ë“œ ìˆ˜ ì´ˆê¸°í™”
    st.session_state.clear()  # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    st.rerun()  # í˜ì´ì§€ ìƒˆë¡œ ê³ ì¹¨

# ìƒˆë¡œìš´ ì„¹ì…˜: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìë™ í…ŒìŠ¤íŠ¸ ë° í‰ê°€
st.sidebar.header("ğŸ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìë™ í…ŒìŠ¤íŠ¸")

# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì…ë ¥ í•„ë“œ
test_cases = st.sidebar.text_area("í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì…ë ¥ (ê° ì¤„ì— í•˜ë‚˜ì”©):", 
                                   "ê°„ë‹¨í•œ ì§ˆë¬¸\në³µì¡í•œ ë¬¸ì œ í•´ê²°\nì°½ì˜ì ì¸ ì‘ì—…")

# í‰ê°€ ê¸°ì¤€ ì„ íƒ
evaluation_criteria = st.sidebar.multiselect(
    "í‰ê°€ ê¸°ì¤€ ì„ íƒ:", 
    [
        "ì •í™•ì„±", 
        "ì¼ê´€ì„±", 
        "ì°½ì˜ì„±", 
        "ì‘ë‹µ ê¸¸ì´", 
        "ë¬¸ë²• ì •í™•ì„±"
    ]
)

# ìë™ í…ŒìŠ¤íŠ¸ ë²„íŠ¼
if st.sidebar.button("ğŸš€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìë™ í…ŒìŠ¤íŠ¸"):
    if not test_cases or not evaluation_criteria:
        st.sidebar.error("í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì™€ í‰ê°€ ê¸°ì¤€ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
        test_results = {
            "prompt_name": selected_prompt_name,
            "prompt_content": selected_prompt_content,
            "test_date": datetime.now().isoformat(),
            "test_cases": []
        }

        # ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì— ëŒ€í•´ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
        for case in test_cases.split('\n'):
            if not case.strip():
                continue

            # AI ì‘ë‹µ ìš”ì²­
            messages = [
                {"role": "system", "content": selected_prompt_content},
                {"role": "user", "content": case}
            ]

            response = completion(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                top_p=top_p,
                stream=False
            )

            ai_response = response.choices[0].message.content

            # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë³„ í‰ê°€
            case_evaluation = {
                "input": case,
                "output": ai_response,
                "evaluations": {}
            }

            # ì„ íƒëœ í‰ê°€ ê¸°ì¤€ì— ë”°ë¼ í‰ê°€ (ì‹¤ì œ í‰ê°€ëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”)
            for criterion in evaluation_criteria:
                if criterion == "ì •í™•ì„±":
                    case_evaluation["evaluations"]["ì •í™•ì„±"] = "ë³´í†µ"  # ì„ì‹œ í‰ê°€
                elif criterion == "ì¼ê´€ì„±":
                    case_evaluation["evaluations"]["ì¼ê´€ì„±"] = "ë†’ìŒ"  # ì„ì‹œ í‰ê°€
                # ë‹¤ë¥¸ í‰ê°€ ê¸°ì¤€ ì¶”ê°€ ê°€ëŠ¥

            test_results["test_cases"].append(case_evaluation)

        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‘œì‹œ
        st.sidebar.success("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        st.sidebar.json(test_results)

        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        test_results_json = json.dumps(test_results, ensure_ascii=False, indent=2)
        st.sidebar.download_button(
            label="í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
            data=test_results_json,
            file_name=f"system_prompt_test_{selected_prompt_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )

        # ì„ íƒì : í‰ê°€ ê²°ê³¼ì— ë”°ë¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìë™ ê°œì„ 
        if st.sidebar.checkbox("í…ŒìŠ¤íŠ¸ ê²°ê³¼ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ìë™ ê°œì„ "):
            # ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ ê°œì„  ë¡œì§ ì¶”ê°€ 
            # ì˜ˆ: OpenAIì˜ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ API ë˜ëŠ” ìì²´ ê°œì„  ì•Œê³ ë¦¬ì¦˜
            st.sidebar.info("í”„ë¡¬í”„íŠ¸ ìë™ ê°œì„  ê¸°ëŠ¥ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    