import streamlit as st
from litellm import completion
from utils import *
import json
from datetime import datetime

st.title("ğŸ’¬ Chat with Simulated AI")

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€
if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
    st.session_state.messages = []  # ë©”ì‹œì§€ ì´ˆê¸°í™”
    st.success("ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")  # ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼

# API í‚¤ ì„¤ì •
with st.sidebar.expander("ğŸ”‘ API Keys", expanded=False):
    api_keys = {}
    for provider, env_var in providers.items():
        api_key = get_api_key(provider, env_var)
        api_keys[provider] = api_key
        if api_key:
            st.success(f"{provider} API Key is set!")

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
system_prompts = load_system_prompts()
if system_prompts:
    st.sidebar.subheader("ğŸ¤– ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸")
    system_template_names = ["ê¸°ë³¸ í”„ë¡¬í”„íŠ¸..."] + [p['name'] for p in system_prompts]
    selected_system_template_1 = st.sidebar.selectbox("ì²« ë²ˆì§¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ:", system_template_names, key="system_prompt_1")
    selected_system_template_2 = st.sidebar.text_area("ë‘ ë²ˆì§¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì…ë ¥:", value="ë‹¤ë¥¸ AIì—ê²Œ ì „ë‹¬í•  ë©”ì‹œì§€ì…ë‹ˆë‹¤.", key="system_prompt_2")

    if selected_system_template_1 != "ê¸°ë³¸ í”„ë¡¬í”„íŠ¸...":
        system_content_1 = next(p['content'] for p in system_prompts if p['name'] == selected_system_template_1)
    else:
        system_content_1 = "You are a helpful assistant."

    system_content_2 = selected_system_template_2 if selected_system_template_2 else "You are a simulated assistant."
else:
    system_content_1 = "You are a helpful assistant."
    system_content_2 = "You are a simulated assistant."

# ëª¨ë¸ ì„ íƒ ë° ì„¤ì •
available_providers = [provider for provider, api_key in api_keys.items() if api_key]
if available_providers:
    selected_provider = st.sidebar.selectbox("Select Provider:", available_providers)
    selected_model = st.sidebar.selectbox(
        "Select Model:",
        provider_models[selected_provider],
        key="model_selector"
    )

    # ë§¤ê°œë³€ìˆ˜ ì„¤ì •
    with st.sidebar.expander("ğŸ® ê³ ê¸‰ ì„¤ì •", expanded=False):
        temperature = st.slider("Temperature:", min_value=0.0, max_value=1.0, value=0.7, step=0.1)
        max_tokens = st.number_input("ìµœëŒ€ í† í° ìˆ˜:", min_value=1, max_value=4096, value=256, step=1)
        top_p = st.slider("Top P:", min_value=0.0, max_value=1.0, value=1.0, step=0.1)
        use_json_format = st.checkbox("JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸°", value=False)
        use_streaming = st.checkbox("Enable streaming", value=True)

        # ëŒ€í™” ë°˜ë³µ íšŸìˆ˜ ì…ë ¥ (ì‚¬ì´ë“œë°”ë¡œ ì´ë™)
        num_iterations = st.number_input("ëŒ€í™” ë°˜ë³µ íšŸìˆ˜:", min_value=1, max_value=10, value=6, step=1)

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ê°„ ëŒ€í™” ë°˜ë³µ
        current_prompt = prompt
        for i in range(num_iterations):
            current_system_content = system_content_1 if i % 2 == 0 else system_content_2
            current_role = "assistant" if i % 2 == 0 else "user"  # ì—­í•  ë²ˆê°ˆì•„ ì„¤ì •

            # ë©”ì‹œì§€ êµ¬ì„±
            # messages = [
            #     {"role": "system", "content": current_system_content},
            #     {"role": "user", "content": current_prompt},
            # ]
            messages = [{"role": "system", "content": current_system_content}] + st.session_state.messages

            # completion params ì„¤ì •
            completion_params = {
                "model": selected_model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "top_p": top_p,
                "stream": use_streaming
            }

            if selected_provider == "Anthropic":
                completion_params["api_key"] = api_keys[selected_provider]
                completion_params["model_name"] = selected_model

            if selected_provider == "Azure":
                completion_params["api_key"] = api_keys[selected_provider]
                completion_params["azure"] = True

            if use_json_format:
                completion_params["response_format"] = {"type": "json_object"}

            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
            response_container = st.empty()
            full_response = ""

            try:
                if use_streaming:
                    for chunk in completion(**completion_params):
                        if selected_provider == "Anthropic":
                            content = chunk.delta.text
                        else:
                            content = chunk.choices[0].delta.content

                        if content:
                            full_response += content
                            response_container.markdown(full_response)
                else:
                    response = completion(**completion_params)
                    if selected_provider == "Anthropic":
                        full_response = response.content
                    else:
                        full_response = response.choices[0].message.content
                    response_container.markdown(full_response)

                # ì‘ë‹µì„ ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                if not st.session_state.messages or st.session_state.messages[-1]["content"] != full_response:
                    st.session_state.messages.append({"role": current_role, "content": full_response})
                    # current_prompt = full_response  # ë‹¤ìŒ AIì˜ ì…ë ¥ìœ¼ë¡œ ì„¤ì •
                    with st.chat_message(current_role):
                        st.markdown(full_response)
                        
                    # AI ì‘ë‹µì„ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì„¤ì •
                    current_prompt = full_response

            except Exception as e:
                st.error(f"Error: {str(e)}")

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    if st.button("ì±„íŒ… íˆìŠ¤í† ë¦¬ ë‹¤ìš´ë¡œë“œ (JSON)"):
        chat_history_json = json.dumps(st.session_state.messages, ensure_ascii=False, indent=2)
        st.download_button(
            label="ì±„íŒ… íˆìŠ¤í† ë¦¬ ë‹¤ìš´ë¡œë“œ",
            data=chat_history_json,
            file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )

else:
    st.sidebar.warning("Please set at least one API key to use the models.") 