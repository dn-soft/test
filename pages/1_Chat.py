import streamlit as st
from litellm import completion
from utils import *
import json
from datetime import datetime

st.title("ğŸ’¬ Chat")

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# API í‚¤ ì„¤ì •
with st.sidebar.expander("ğŸ”‘ API Keys", expanded=False):
    api_keys = {}
    for provider, env_var in providers.items():
        api_key = get_api_key(provider, env_var)
        api_keys[provider] = api_key
        if api_key:
            st.success(f"{provider} API Key is set!")

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
system_prompts = load_system_prompts()
if system_prompts:
    st.sidebar.subheader("ğŸ¤– ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸")
    system_template_names = ["ê¸°ë³¸ í”„ë¡¬í”„íŠ¸..."] + [p['name'] for p in system_prompts]
    selected_system_template = st.sidebar.selectbox("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ:", system_template_names)
    
    if selected_system_template != "ê¸°ë³¸ í”„ë¡¬í”„íŠ¸...":
        system_content = next(p['content'] for p in system_prompts if p['name'] == selected_system_template)
    else:
        system_content = "You are a helpful assistant."
else:
    system_content = "You are a helpful assistant."

# ëª¨ë¸ ì„ íƒ
available_providers = [provider for provider, api_key in api_keys.items() if api_key]
if available_providers:
    selected_provider = st.sidebar.selectbox("Select Provider:", available_providers)
    selected_model = st.sidebar.selectbox(
        "Select Model:",
        provider_models[selected_provider],
        key="model_selector"
    )

    # ë§¤ê°œë³€ìˆ˜ ì„¤ì •
    with st.sidebar.expander("ğŸ® ê³ ê¸‰ ì„¤ì •", expanded=False):
        temperature = st.slider("Temperature:", min_value=0.0, max_value=1.0, value=0.7, step=0.1)
        max_tokens = st.number_input("ìµœëŒ€ í† í° ìˆ˜:", min_value=1, max_value=4096, value=256, step=1)
        top_p = st.slider("Top P:", min_value=0.0, max_value=1.0, value=1.0, step=0.1)
        use_json_format = st.checkbox("JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸°", value=False)
        use_streaming = st.checkbox("Enable streaming", value=True)

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ì‘ë‹µ
        with st.chat_message("assistant"):
            # ì „ì²´ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ êµ¬ì„±
            messages = [
                {"role": "system", "content": system_content}
            ] + st.session_state.messages

            # completion params ì„¤ì •
            completion_params = {
                "model": selected_model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "top_p": top_p,
                "stream": use_streaming
            }

            if selected_provider == "Anthropic":
                completion_params["api_key"] = api_keys[selected_provider]
                completion_params["model_name"] = selected_model

            if selected_provider == "Azure":
                completion_params["api_key"] = api_keys[selected_provider]
                completion_params["azure"] = True

            if use_json_format:
                completion_params["response_format"] = {"type": "json_object"}

            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
            response_container = st.empty()
            full_response = ""
            
            try:
                if use_streaming:
                    for chunk in completion(**completion_params):
                        if selected_provider == "Anthropic":
                            content = chunk.delta.text
                        else:  # OpenAI, Azure
                            content = chunk.choices[0].delta.content
                            
                        if content:
                            full_response += content
                            response_container.markdown(full_response)
                else:
                    response = completion(**completion_params)
                    if selected_provider == "Anthropic":
                        full_response = response.content
                    else:
                        full_response = response.choices[0].message.content
                    response_container.markdown(full_response)

                # ì‘ë‹µì„ ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                
            except Exception as e:
                st.error(f"Error: {str(e)}")

    # ì±„íŒ… ê´€ë¦¬ ì„¹ì…˜ (ì‚¬ì´ë“œë°” í•˜ë‹¨ì— ì¶”ê°€)
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ’¾ ì±„íŒ… ê´€ë¦¬")
    
    # ì±„íŒ… ì €ì¥ ë²„íŠ¼
    if st.session_state.messages:  # ë©”ì‹œì§€ê°€ ìˆì„ ë•Œë§Œ ì €ì¥ ë²„íŠ¼ í‘œì‹œ
        if st.sidebar.button("í˜„ì¬ ì±„íŒ… ì €ì¥"):
            file_path = save_chat_history(st.session_state.messages)
            if file_path:
                st.sidebar.success(f"ì±„íŒ…ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ì €ì¥ëœ ì±„íŒ… ë¶ˆëŸ¬ì˜¤ê¸°
    st.sidebar.markdown("#### ì €ì¥ëœ ì±„íŒ…")
    histories = list_chat_histories()
    if histories:
        selected_history = st.sidebar.selectbox(
            "ì €ì¥ëœ ì±„íŒ… ì„ íƒ:",
            options=histories,
            format_func=lambda x: f"{x['filename']} ({x['message_count']}ê°œì˜ ë©”ì‹œì§€)"
        )
        
        col1, col2, col3 = st.sidebar.columns(3)
        with col1:
            if st.button("ë¶ˆëŸ¬ì˜¤ê¸°"):
                messages = load_chat_history(selected_history['file_path'])
                if messages:
                    st.session_state.messages = messages
                    st.rerun()
        with col2:
            if st.button("ì‚­ì œ"):
                try:
                    os.remove(selected_history['file_path'])
                    st.success("ì±„íŒ…ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
                except Exception as e:
                    st.error(f"ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        with col3:
            # JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            try:
                with open(selected_history['file_path'], 'r', encoding='utf-8') as f:
                    json_data = f.read()
                    
                st.download_button(
                    label="ë‹¤ìš´ë¡œë“œ",
                    data=json_data,
                    file_name=selected_history['filename'],
                    mime="application/json"
                )
            except Exception as e:
                st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
    else:
        st.sidebar.info("ì €ì¥ëœ ì±„íŒ…ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # í˜„ì¬ ì±„íŒ… ë‚´ë³´ë‚´ê¸° (JSON ë‹¤ìš´ë¡œë“œ)
    if st.session_state.messages:
        st.sidebar.markdown("#### í˜„ì¬ ì±„íŒ… ë‚´ë³´ë‚´ê¸°")
        current_chat_json = json.dumps({
            "messages": st.session_state.messages,
            "exported_at": datetime.now().isoformat()
        }, ensure_ascii=False, indent=2)
        
        st.sidebar.download_button(
            label="í˜„ì¬ ì±„íŒ… ë‹¤ìš´ë¡œë“œ",
            data=current_chat_json,
            file_name=f"chat_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    # ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
    st.sidebar.markdown("---")
    if st.sidebar.button("ğŸ—‘ï¸ ì±„íŒ… ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

else:
    st.sidebar.warning("Please set at least one API key to use the models.")